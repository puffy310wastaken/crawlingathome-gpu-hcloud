{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('gpuhcloud': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "interpreter": {
      "hash": "bc322c11e8113b1b1dfcd753c5702c5c5d95a81c495f9a7060b170a2a7888bca"
    },
    "colab": {
      "name": "gpuclient.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfrhp_L1o1IC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81ab795-8125-48c5-a21a-d04e74f63327"
      },
      "source": [
        "! git clone \"https://github.com/TheoCoombes/crawlingathome\" crawlingathome_client\n",
        "! pip3 install -r crawlingathome/requirements.txt --no-cache-dir\n",
        "! rm requirements.txt\n",
        "! wget https://raw.githubusercontent.com/rvencu/crawlingathome-gpu-hcloud/staged-clients/requirements.txt\n",
        "! wget https://raw.githubusercontent.com/puffy310wastaken/crawlingathome-gpu-hcloud/main/utils.py\n",
        "! pip3 install -r ./requirements.txt --no-cache-dir\n",
        "! pip3 install ftfy pandas tfr_image\n",
        "! pip3 install tensorflow --no-cache-dir\n",
        "! pip3 install clip-anytorch\n",
        "! pip3 install bloom-filter2\n",
        "! pip3 install colorama\n",
        "! pip3 install ray\n",
        "! yes | pip3 uninstall pillow\n",
        "! CC=\"cc -mavx2\" pip3 install -U --force-reinstall pillow-simd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'crawlingathome_client' already exists and is not an empty directory.\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'crawlingathome/requirements.txt'\u001b[0m\n",
            "rm: cannot remove 'requirements.txt': No such file or directory\n",
            "--2021-10-01 04:27:37--  https://raw.githubusercontent.com/rvencu/crawlingathome-gpu-hcloud/staged-clients/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2021-10-01 04:27:37 ERROR 404: Not Found.\n",
            "\n",
            "--2021-10-01 04:27:37--  https://raw.githubusercontent.com/puffy310wastaken/crawlingathome-gpu-hcloud/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40918 (40K) [text/plain]\n",
            "Saving to: ‘utils.py.1’\n",
            "\n",
            "utils.py.1          100%[===================>]  39.96K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-10-01 04:27:37 (34.1 MB/s) - ‘utils.py.1’ saved [40918/40918]\n",
            "\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './requirements.txt'\u001b[0m\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tfr_image in /usr/local/lib/python3.7/dist-packages (1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.40.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n",
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_criteria_to_update(candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 202, in _get_criteria_to_update\n",
            "    for r in self._p.get_dependencies(candidate=candidate):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in get_dependencies\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 175, in <listcomp>\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 419, in iter_dependencies\n",
            "    for r in self.dist.requires():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1425, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1514, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1524, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1586, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 894, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 208, in format\n",
            "    msg = super().format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/logging.py\", line 138, in format\n",
            "    formatted = \"\".join([prefix + line for line in formatted.splitlines(True)])\n",
            "KeyboardInterrupt\n",
            "Requirement already satisfied: bloom-filter2 in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxnfP5Z5o1IG"
      },
      "source": [
        "#@title Crawling at Home - GPU worker\n",
        "YOUR_NICKNAME_FOR_THE_LEADERBOARD = \"puffy310\" #@param {type:\"string\"}\n",
        "groupsize = \"15\" #@param {type:\"string\"}\n",
        "CRAWLINGATHOME_SERVER_URL = \"http://cah.io.community/\"\n",
        "groupsize = int(groupsize)\n",
        "gpunum = 1 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RveS0eB-o1IH"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "import clip\n",
        "import shutil\n",
        "import torch\n",
        "import threading\n",
        "import ray\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from colorama import Fore\n",
        "from statistics import mode\n",
        "import crawlingathome_client as cah\n",
        "from bloom_filter2 import BloomFilter\n",
        "sys.path.append('./crawlingathome-worker/')\n",
        "from multiprocessing import JoinableQueue, Process\n",
        "\n",
        "if not os.path.exists(\"./stats/\"):\n",
        "    os.makedirs(\"./stats/\")\n",
        "if not os.path.exists(\"./save/\"):\n",
        "    os.makedirs(\"./save/\")\n",
        "\n",
        "# initial cleanup - delete all working files in case of crash recovery\n",
        "reg_compile = re.compile(r\"^\\d{1,3}-\\d{1,3}-\\d{1,3}-\\d{1,3}$\")\n",
        "for root, dirnames, filenames in os.walk(\".\"):\n",
        "    for filename in filenames:\n",
        "        if filename.startswith(\"gpujob.zip_\"):\n",
        "            os.remove(filename)\n",
        "    for dir in dirnames:\n",
        "        if reg_compile.match(dir):\n",
        "            shutil.rmtree(dir)\n",
        "re_uuid = re.compile(r'[0-9a-f]{32}', re.I)\n",
        "for root, dirnames, filenames in os.walk(\".\"):\n",
        "    for dir in dirnames:\n",
        "        if re_uuid.match(dir):\n",
        "            shutil.rmtree(dir)\n",
        "re_gz = re.compile(r'.*.tar.gz.*', re.I)\n",
        "for root, dirnames, filenames in os.walk(\".\"):\n",
        "    for file in filenames:\n",
        "        if re_gz.match(file):\n",
        "            os.remove(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqECcRspo1IJ"
      },
      "source": [
        "#initialize joinable queues to transfer messages between multiprocess processes\n",
        "# Outbound queues, we need one for each io worker\n",
        "outbound = []\n",
        "for _ in range(int(2.7 * groupsize)): # we need 2x IO workers to keep GPU permanently busy\n",
        "        outbound.append(JoinableQueue())\n",
        "inbound = JoinableQueue()\n",
        "uploadqueue = JoinableQueue()\n",
        "counter = JoinableQueue()\n",
        "inpsize = JoinableQueue() # use this to communicate number of jobs downloading now\n",
        "gpuflag = JoinableQueue() # use this to flag that gpu is processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FgdJglv2TXu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TER_QFJ1o1IJ"
      },
      "source": [
        "# define CLIP class around OpenAI clip model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nta47xldo1IK"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "class CLIPDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, preprocess):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_transform = preprocess\n",
        "        self.tokenizer = clip.tokenize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.dataframe.iloc[index]\n",
        "        return (\n",
        "            self.image_transform(Image.open(row[\"PATH\"])),\n",
        "            self.tokenizer(row[\"TEXT\"], truncate=True)[0],\n",
        "        )\n",
        "\n",
        "class CLIP:\n",
        "    def __init__(self):\n",
        "        self.model, self.preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
        "        self.cosine_similarity = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        with torch.no_grad():\n",
        "            self.categories = self.model.encode_text(clip.tokenize([\"neutral\",\"selfie\", \"illustration, drawing\", \"toys, play, kids, children\", \"teddy bear, puppet\", \"animal, bird, mammal, insect\" \"fashion, clothes\", \"logo, commercial, ad, advertisement\", \"drawing, painting\",\"anime, cartoon\",\"comedy, fun\",\"romance, love story\",\"thriller, suspense, crime story\",\"action, action movie\", \"horror, monster movie\", \"documentary\", \"news, journalism\", \"entertainment\", \"talk show\", \"porn, sex, sperm, nipples, breats, tits, boops, penis, dick, cock, clitoris, vagina, fuck, lust, horny, sexual, lick, licking\",  \"porn, sex, sperm, nipples\", \"porn, sex, sperm, penis, dick, cock\", \"nipples, breats, tits, boops, sexy\", \"penis, dick, cock\", \"clitoris, vagina\", \"sex, fuck, lust, horny, sexual, lick, licking\", \"porn, sex, sexy\",\"sexy, hot\",\"sperm, skin\",\"lust, horny, sexual\",\"lick, licking, body\", \"anime, hentai, sexy\", \"cartoon, sexy, sex\", \"hentai\", \"anime, sexy, breasts\", \"hentai\"]).to(device))\n",
        "            self.underaged_categories = self.model.encode_text(clip.tokenize([\"teenager, teen\", \"kid, child, teenager, teen, baby or toddler, underaged, little girl, little boy\", \"kid, child, little girl, little boy\", \"baby, toddler\",\"adult, woman, man, grownup, grown person,full-aged of legal age\",\"full-aged, of legal age, adult\",\"woman, man\",\"adult, woman, man, grownup, grown person,full-aged of legal age\"]).to(device))\n",
        "            self.animal_categories = self.model.encode_text(clip.tokenize([\"lifeless object, thing\", \"thing, object\", \"material\", \"furniture\",\"wall\", \"house\", \"tree\", \"wood\",\"ground\",\"industry\", \"table\", \"bed\", \"tool\", \"dress, clothes\", \"door\", \"chair\", \"rock, stone\", \"human\", \"man\", \"woman\", \"man, woman\", \"animal\",\"cat\",\"dog\", \"cow\", \"pig\", \"goat\", \"sheep\", \"elephant\", \"horse\", \"horse, elephant, pig, dog, cat, sheep, goat, animal\", \"life\", \"wildlife\"]).to(device))\n",
        "\n",
        "    def similarity_imgalt(self, image_tensor, text_tokens):\n",
        "        with torch.no_grad():\n",
        "            image_features = self.model.encode_image(image_tensor.to(device)).float()\n",
        "            text_features = self.model.encode_text(text_tokens.to(device)).float()\n",
        "            similarity = self.cosine_similarity(image_features, text_features).tolist()\n",
        "\n",
        "        image_features = image_features.detach().cpu().numpy()\n",
        "        return image_features, similarity\n",
        "\n",
        "    def preprocess_images(self, df):\n",
        "        ret_image_features = []\n",
        "        ret_similarity = []\n",
        "        batch_size = 256 if device == \"cuda\" else 8\n",
        "        dataset = CLIPDataset(df, self.preprocess)\n",
        "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=int(2*cpu_count()/3), pin_memory=True)\n",
        "        for tensors, tokens in dataloader:\n",
        "            image_features, similarities = self.similarity_imgalt(tensors, tokens)\n",
        "            ret_image_features.extend(image_features)\n",
        "            ret_similarity.extend(similarities)\n",
        "        return ret_image_features, ret_similarity\n",
        "\n",
        "    def prob(self, image_features, text_features):\n",
        "        text_features = text_features.float()\n",
        "        image_features = torch.as_tensor(image_features).to(device, dtype=torch.float32)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # cosine similarity as logits\n",
        "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "        _, indices = similarity.topk(2)\n",
        "        return indices\n",
        "\n",
        "\n",
        "clip_filter = CLIP()\n",
        "\n",
        "\n",
        "def df_clipfilter(df):\n",
        "    sim_threshold = 0.3\n",
        "    underaged_text = [\"teen\", \"kid\", \"child\", \"baby\"]\n",
        "\n",
        "    img_embedding, similarities = clip_filter.preprocess_images(df)\n",
        "    tmp_embed = []\n",
        "\n",
        "    for i, img_embed in enumerate(img_embedding):\n",
        "        if similarities[i] < sim_threshold:\n",
        "            #df.drop(i, inplace=True)\n",
        "            df.at[i, 'dropped'] = True\n",
        "            continue\n",
        "\n",
        "        # get most similar categories\n",
        "        nsfw_prob = clip_filter.prob(img_embed, clip_filter.categories)\n",
        "        df.at[i, \"NSFW\"] = \"UNSURE\"\n",
        "        df.at[i, \"similarity\"] = similarities[i]\n",
        "        if nsfw_prob[0] < 19 and nsfw_prob[1] < 19:\n",
        "            df.at[i, \"NSFW\"] = \"UNLIKELY\"\n",
        "            tmp_embed.append(img_embed)\n",
        "            continue\n",
        "        elif nsfw_prob[0] >= 19 and nsfw_prob[1] >= 19:\n",
        "            df.at[i, \"NSFW\"] = \"NSFW\"\n",
        "\n",
        "        underage_prob = clip_filter.prob(img_embed, clip_filter.underaged_categories)\n",
        "        if underage_prob[0] < 4 or underage_prob[1] < 4 or any(x in df.at[i, \"TEXT\"] for x in underaged_text):\n",
        "            #df.drop(i, inplace=True)\n",
        "            df.at[i, 'dropped'] = True\n",
        "            continue\n",
        "\n",
        "        animal_prob = clip_filter.prob(img_embed, clip_filter.animal_categories)\n",
        "        if animal_prob[0] > 20:\n",
        "            #df.drop(i, inplace=True)\n",
        "            df.at[i, 'dropped'] = True\n",
        "            continue\n",
        "        tmp_embed.append(img_embed)\n",
        "        df.at[i, 'dropped'] = False\n",
        "        \n",
        "    df = df[df[\"dropped\"] != True]\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    return tmp_embed, df\n",
        "\n",
        "\n",
        "def df_tfrecords(df, output_fname):\n",
        "    import tensorflow as tf\n",
        "    from tfr_image.utils import bytes_feature, int64_feature\n",
        "\n",
        "    def image_to_tfexample(sample_id, image_data, image_format, height, width, caption):\n",
        "        return tf.train.Example(\n",
        "            features=tf.train.Features(\n",
        "                feature={\n",
        "                    \"sampleID\": bytes_feature(sample_id),\n",
        "                    \"image\": bytes_feature(image_data),\n",
        "                    \"format\": bytes_feature(image_format),\n",
        "                    \"label\": bytes_feature(caption),\n",
        "                    \"height\": int64_feature(height),\n",
        "                    \"width\": int64_feature(width),\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "\n",
        "    with tf.io.TFRecordWriter(output_fname) as tfrecord_writer:\n",
        "        for i in range(len(df)):\n",
        "            df_image = df.iloc[i]\n",
        "            image_fname = df_image[\"PATH\"]\n",
        "            file_type = image_fname.split(\".\")[-1]\n",
        "            with tf.io.gfile.GFile(image_fname, \"rb\") as f:\n",
        "                image_data = f.read()\n",
        "            example = image_to_tfexample(\n",
        "                str(df_image[\"SAMPLE_ID\"]).encode(\"utf_8\"),\n",
        "                image_data,\n",
        "                file_type.encode(\"utf_8\"),\n",
        "                df_image[\"HEIGHT\"],\n",
        "                df_image[\"WIDTH\"],\n",
        "                df_image[\"TEXT\"].encode(\"utf_8\"),\n",
        "            )\n",
        "            tfrecord_writer.write(example.SerializeToString())\n",
        "\n",
        "\n",
        "def filter(df, out_fname, output_folder):\n",
        "    results = []\n",
        "    #start0 = start = time.time()\n",
        "    img_embeddings, dff = df_clipfilter(df)\n",
        "    dff.to_csv(f\"{output_folder}{out_fname}.csv\", index=False, sep=\"|\")\n",
        "\n",
        "    #count results for each worker from resulting dff\n",
        "    dff[\"shard\"] = dff.apply(lambda row: str(row.PATH).split(\"/\")[1], axis=1)\n",
        "    results = dff[\"shard\"].value_counts()\n",
        "    #print(f\"CLIP ran in {round(time.time()-start,2)}\")\n",
        "    #start = time.time()\n",
        "    img_embeds_sampleid = {}\n",
        "    for i, img_embed_it in enumerate(img_embeddings):\n",
        "        dfid_index = dff.at[i, \"SAMPLE_ID\"]\n",
        "        img_embeds_sampleid[str(dfid_index)] = img_embed_it\n",
        "    with open(f\"{output_folder}image_embedding_dict-{out_fname}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(img_embeds_sampleid, f)\n",
        "    #print(f\"Embeddings ran in {round(time.time()-start,2)}\")\n",
        "    #start = time.time()\n",
        "    df_tfrecords(\n",
        "        dff,\n",
        "        f\"{output_folder}crawling_at_home_{out_fname}__00000-of-00001.tfrecord\",\n",
        "    )\n",
        "    #print(f\"Tfrecords ran in {round(time.time()-start,2)}\")\n",
        "    #print(f\"Job ran in {round(time.time()-start0,2)}\")\n",
        "    return len(dff), results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Vv_2voo1IM"
      },
      "source": [
        "# define workers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lz_T9Cheo1IM"
      },
      "source": [
        "def gpu_cah_interface(i:int, incomingqueue: JoinableQueue, outgoingqueue: JoinableQueue, YOUR_NICKNAME_FOR_THE_LEADERBOARD, CRAWLINGATHOME_SERVER_URL):\n",
        "    # initiate and reinitiate a GPU type client if needed\n",
        "    print (f\"   |___ inbound worker started\")\n",
        "    while True:\n",
        "        client = cah.init(\n",
        "            url=CRAWLINGATHOME_SERVER_URL, nickname=YOUR_NICKNAME_FOR_THE_LEADERBOARD, type=\"GPU\"\n",
        "        )\n",
        "        while client.isAlive():\n",
        "            while client.jobCount() > 0: \n",
        "                # each thread gets a new job, passes it to GPU then waits for completion\n",
        "                try:\n",
        "                    client.newJob()\n",
        "                except:\n",
        "                    time.sleep(10)\n",
        "                    continue\n",
        "                job = \"\"\n",
        "                try:\n",
        "                    job = client.shard.split(\" \")[1]\n",
        "                except:\n",
        "                    client.invalidURL()\n",
        "                    print (f\"[io {i}] invalid job detected: {job}\")\n",
        "                    continue\n",
        "                # found repeating shards, need to clear old files before continuing\n",
        "                if os.path.exists(\"./\"+ job):\n",
        "                    shutil.rmtree(\"./\"+ job, ignore_errors=True)\n",
        "                os.mkdir(\"./\"+ job)\n",
        "                client.downloadShard()\n",
        "\n",
        "                if len(glob(f\"{job}/*.csv\")) == 0:\n",
        "                    client.invalidURL()\n",
        "                    print (f\"[io {i}] invalid job detected: {job}\")\n",
        "                    continue\n",
        "                for file in glob(f\"{job}/*_parsed.csv\"):\n",
        "                    os.system(f\"mv {file} stats/\")\n",
        "                for file in glob(f\"{job}/*_unfiltered.csv\"):\n",
        "                    os.system(f\"mv {file} stats/\")\n",
        "                #print (f\"[io] job sent to GPU: {job}\")\n",
        "                incomingqueue.put((i, job, client.upload_address))\n",
        "                \n",
        "                # wait until job gets processes\n",
        "                while True:\n",
        "                    if outgoingqueue.qsize() > 0:\n",
        "                        outjob, pairs = outgoingqueue.get() # I am poping out from queue only if my current job is finished\n",
        "                        print (f\"[io] received results for: {job}={outjob}\")\n",
        "                        outgoingqueue.task_done()\n",
        "                        if pairs > 0:\n",
        "                            print (f\"[io] mark job as complete: {job}\")\n",
        "                            try:\n",
        "                                client.completeJob(int(pairs))\n",
        "                            except:\n",
        "                                pass\n",
        "                        shutil.rmtree(\"./\"+ job)\n",
        "                        break # we can let the worker request a new job\n",
        "                    else:\n",
        "                        time.sleep(1)\n",
        "            else:\n",
        "                print (f\"[io] no jobs\")\n",
        "                time.sleep(10)\n",
        "        else:\n",
        "            print (f\"[io] client forgotten\")\n",
        "            time.sleep(10)\n",
        "\n",
        "def io_worker(incomingqueue: JoinableQueue, outgoingqueue: list, groupsize: int, YOUR_NICKNAME_FOR_THE_LEADERBOARD, CRAWLINGATHOME_SERVER_URL):\n",
        "    # separate process to initialize threaded workers\n",
        "    print (f\"[io] inbound workers:\")\n",
        "    try:\n",
        "        # just launch how many threads we need to group jobs into single output\n",
        "        for i in range(2 * groupsize):\n",
        "            threading.Thread(target=gpu_cah_interface, args=(i, incomingqueue, outgoingqueue[i], YOUR_NICKNAME_FOR_THE_LEADERBOARD, CRAWLINGATHOME_SERVER_URL)).start()\n",
        "    except Exception as e:\n",
        "        print(f\"[io] some inbound problem occured: {e}\")\n",
        "\n",
        "@ray.remote(num_gpus = 1)\n",
        "def gpu_worker(incomingqueue: JoinableQueue, outgoingqueue: list, counter: JoinableQueue, gpuflag: JoinableQueue, groupsize: int):\n",
        "    print (f\"[gpu] worker started\")\n",
        "    # watch for the incoming queue, when it is big enough we can trigger processing    \n",
        "    while True:\n",
        "        print (f\"[gpu] testing incoming queue size\")\n",
        "        if incomingqueue.qsize() >= groupsize:\n",
        "            gpuflag.put(1)\n",
        "            shards = []\n",
        "            addresses = []\n",
        "            group_id = uuid.uuid4().hex\n",
        "            print (f\"[gpu] got new {groupsize} jobs to group in id {group_id}\")\n",
        "            group_parse = None\n",
        "            for _ in range(groupsize):\n",
        "                i, job, address = incomingqueue.get()\n",
        "\n",
        "                all_csv = ray.put([])\n",
        "                all_csv_files = ray.get(all_csv)\n",
        "                del all_csv\n",
        "                for path, subdir, files in os.walk(job):\n",
        "                    for file in glob(os.path.join(path, \"*.csv\")):\n",
        "                        all_csv_files.append(file)\n",
        "                # get name of csv file\n",
        "                out_path = all_csv_files[0]\n",
        "                shards.append((i, job, Path(out_path).stem.strip(\"_unfiltered\").strip(\"_parsed\").strip(\".\")))\n",
        "                addresses.append(address)\n",
        "\n",
        "                incomingqueue.task_done()\n",
        "            print (f\"[gpu] adjusted image paths\")\n",
        "\n",
        "            for i, job, item in shards:\n",
        "                dlparse_df = pd.read_csv(job + \"/\" + item + \".csv\", sep=\"|\")\n",
        "                dlparse_df[\"PATH\"] = dlparse_df.apply(lambda x: \"./\" + job + \"/\" + x[\"PATH\"].strip(\"save/\"), axis=1)\n",
        "                if group_parse is None:\n",
        "                    group_parse = dlparse_df\n",
        "                else:\n",
        "                    group_parse = group_parse.append(dlparse_df, ignore_index=True)\n",
        "                \n",
        "            with open(\"./save/\" + group_id + \".txt\", \"wt\") as f:\n",
        "                for i, job, item in shards:\n",
        "                    f.write(item + \"\\n\")\n",
        "            \n",
        "            print (f\"[gpu] saving stats\")\n",
        "\n",
        "            group_parse.to_csv(\"./stats/\" + group_id + \"_groupduped.csv\", index=False, sep=\"|\") # I am using these to find out domains to filter from scraping\n",
        "            group_parse.drop_duplicates(subset=[\"URL\",\"TEXT\"], keep='last', inplace=True)\n",
        "            group_parse.reset_index(inplace=True, drop=True)\n",
        "\n",
        "            group_parse.to_csv(\"./stats/\" + group_id + \"_groupdeduped.csv\", index=False, sep=\"|\") # I am using these to find out domains to filter from scraping\n",
        "\n",
        "            print (f\"[gpu] sending group to CLIP filter\")\n",
        "            start = time.time()\n",
        "            final_images, results = filter(group_parse, group_id, \"./save/\")\n",
        "            \n",
        "            total = len(group_parse.index)\n",
        "            dedupe_ratio = round((duped - total) / duped, 2)\n",
        "            print(f\"filtered {final_images} from {total} deduped from {duped} (dedupe ratio {dedupe_ratio}) in {round(time.time()-start,2)} sec ({groupsize})\")\n",
        "\n",
        "            print (f\"[gpu] upload group results to rsync target\")\n",
        "            # find most required upload address among the grouped shards\n",
        "            upload_address = mode(addresses)\n",
        "            print (f\"most requested upload address is {upload_address}\")\n",
        "            response = os.system(f\"rsync -zh --remove-source-files save/*{group_id}* {upload_address}\") # to do get target from client\n",
        "            if response == 0:\n",
        "                print (f\"[gpu] sending all jobs to be marked as completed\")\n",
        "                for i, job, item in shards:\n",
        "                    outgoingqueue[i].put((job, results.get(job)))\n",
        "                    counter.put(1)\n",
        "            else:\n",
        "                for i, job, item in shards:\n",
        "                    outgoingqueue[i].put((job, 0)) # if upload crashes, then do NOT mark completeJob()\n",
        "            print (f\"[gpu] cleaning up group folders\")\n",
        "\n",
        "            if final_images < 7500:\n",
        "                groupsize += 2\n",
        "                print (f\"groupsize changed to {groupsize}\")\n",
        "            if final_images > 8500:\n",
        "                groupsize -= 2\n",
        "                print (f\"groupsize changed to {groupsize}\")\n",
        "            \n",
        "            gpuflag.get()\n",
        "            gpuflag.task_done()\n",
        "        else:\n",
        "            time.sleep(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v4N4JClo1IO"
      },
      "source": [
        "# start all processes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMFi5wyso1IP"
      },
      "source": [
        "io = Process(target=io_worker, args=[inbound, outbound, groupsize, YOUR_NICKNAME_FOR_THE_LEADERBOARD, CRAWLINGATHOME_SERVER_URL], daemon=True).start()\n",
        "\n",
        "gpu_work = ray.get([gpu_worker.remote(inbound, outbound, counter, gpuflag, groupsize) for X in range(gpunum)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}